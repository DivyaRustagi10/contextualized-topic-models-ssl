{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivyaRustagi10/contextualized-topic-models-ssl/blob/main/ZeroshotTM_Parent_Paper_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEYfwujnu5Wh"
      },
      "source": [
        "#To contextualize or to not contextualize?\n",
        "\n",
        "> Can we define a topic model that does not rely on the BoW input but instead uses contextual information?\n",
        "\n",
        "First, we want to check if ZeroShotTM maintains comparable performance to other topic models; if this is true, we can then explore its performance in\n",
        "a cross-lingual setting. Since we use only English text, in this setting we use English representations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3H5Cn_ftZzW"
      },
      "outputs": [],
      "source": [
        "# Install the contextualized topic model library\n",
        "%%capture\n",
        "!pip install contextualized-topic-models==2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vht2fQJ6uqvh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyldavis\n",
        "!pip install wget\n",
        "!pip install head"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdXtmHGUwlYL",
        "outputId": "2d0beb04-48ad-46f4-a395-e5d0f369ffa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 31 20:50:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOSAecV9wQGP"
      },
      "source": [
        "We replace the input BoW in Neural-ProdLDA\n",
        "with pre-trained multilingual representations from\n",
        "SBERT (Reimers and Gurevych, 2019), a recent and effective model for contextualized representations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdhn10XNwVL1"
      },
      "source": [
        "Indeed, ZeroShotTM\n",
        "is language-independent: given a contextualized\n",
        "representation of a new language as input,1\n",
        "it can\n",
        "predict the topic distribution of the document. The\n",
        "predicted topic descriptors, though, will be from\n",
        "the training language. Let us also notice that our\n",
        "method is agnostic about the choice of the neural\n",
        "topic model architecture (here, Neural-ProdLDA),\n",
        "as long as it extends a Variational Autoencoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnXnkp3TxGYy"
      },
      "source": [
        "### Data\n",
        "\n",
        "**Building W1**\n",
        "\n",
        "We use datasets collected from English\n",
        "Wikipedia abstracts from DBpedia. The first dataset (W1) contains 20,000 randomly sampled abstracts. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRYo3hb4zUTf"
      },
      "source": [
        "**Downloading DBPedia 20K Abstracts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p7ROk_X9zXH_",
        "outputId": "f49fac13-6156-4950-ff70-07de18811c8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dbpedia_sample_abstract_20k_unprep (1).txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import wget\n",
        "wget.download(\"https://raw.githubusercontent.com/vinid/data/master/dbpedia_sample_abstract_20k_unprep.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP8KlaHlzkLa"
      },
      "outputs": [],
      "source": [
        "text_file = \"dbpedia_sample_abstract_20k_unprep.txt\" # EDIT THIS WITH THE FILE YOU UPLOAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkbIsafEz6w3"
      },
      "source": [
        "**Preprocessing**\n",
        "\n",
        "Why do we use the preprocessed text here? We need text without punctuation to build the bag of word. Also, we might want only to have the most frequent words inside the BoW. Too many words might not help."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQBKiAC_z_aj",
        "outputId": "f0c4a5d9-d5d9-4a48-e185-5145c4f22618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "documents = [line.strip() for line in open(text_file, encoding=\"utf-8\").readlines()]\n",
        "sp = WhiteSpacePreprocessing(documents, stopwords_language='english')\n",
        "preprocessed_documents, unpreprocessed_corpus, vocab = sp.preprocess()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnIptVxk0F4n"
      },
      "source": [
        "We don't discard the non-preprocessed texts, because we are going to use them as input for obtaining the contextualized document representations.\n",
        "\n",
        "Let's pass our files with preprocess and unpreprocessed data to our TopicModelDataPreparation object. This object takes care of creating the bag of words for you and of obtaining the contextualized BERT representations of documents. This operation allows us to create our training dataset.\n",
        "\n",
        "Note: Here we use the contextualized model \"distiluse-base-multilingual-cased\", because we need a multilingual model for performing cross-lingual predictions later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training ZeroshotTM**"
      ],
      "metadata": {
        "id": "C5dx85bGx7eu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erO2thoszs7P"
      },
      "outputs": [],
      "source": [
        "from contextualized_topic_models.models.ctm import ZeroShotTM\n",
        "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
        "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessing\n",
        "import nltk\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO-88XsA0G6m"
      },
      "outputs": [],
      "source": [
        "# Load English SBERT embeddings\n",
        "tp = TopicModelDataPreparation(\"sentence-transformers/bert-base-nli-mean-tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfKQcrICxfb-"
      },
      "outputs": [],
      "source": [
        "# Building training dataset\n",
        "training_dataset = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvN6JTLT0PMj"
      },
      "source": [
        "### Training Models\n",
        "\n",
        "**M1. Training Zero-Shot Contextualized Topic Model**\n",
        "\n",
        "Finally, we can fit our new topic model. We will ask the model to find 50 topics in our collection (n_component parameter of the CTM object)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGDIur9O0Qa_"
      },
      "outputs": [],
      "source": [
        "# Train over 100 epochs\n",
        "ctm = ZeroShotTM(bow_size=len(tp.vocab), contextual_size=768, batch_size = 200, n_components = 50)\n",
        "ctm_100 = ZeroShotTM(bow_size=len(tp.vocab), contextual_size=768, batch_size = 200, n_components = 100)\n",
        "ctm.fit(training_dataset, save_dir = \"./\") # run the model\n",
        "ctm_100.fit(training_dataset, save_dir = \"./\") # run the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucgzwNqP0YA6"
      },
      "source": [
        "After training, now it is the time to look at our topics: we can use the\n",
        "\n",
        "\n",
        "```\n",
        "get_topic_lists\n",
        "```\n",
        "function to get the topics. It also accepts a parameter that allows you to select how many words you want to see for each topic.\n",
        "\n",
        "If you look at the topics, you will see that they all make sense and are representative of a collection of documents that comes from Wikipedia (general knowledge). Notice that the topics are in English, because we trained the model on English documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrYUpAUhRohf"
      },
      "outputs": [],
      "source": [
        "# Check topics\n",
        "ctm.get_topic_lists(5)\n",
        "ctm_100.get_topic_lists(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsbwFDx9QtYr"
      },
      "outputs": [],
      "source": [
        "# Topic Predictions\n",
        "topics_predictions = ctm.get_thetas(training_dataset, n_samples=30) # get all the topic predictions\n",
        "topics_predictions_100 = ctm_100.get_thetas(training_dataset, n_samples=30) # get all the topic predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTobj2_LtNWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8dca526-442d-429a-ba8e-ad85b5cf361a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16294250186748438\n",
            "0.1477697544158918\n"
          ]
        }
      ],
      "source": [
        "# Get NPMI Coherence\n",
        "from contextualized_topic_models.evaluation.measures import CoherenceNPMI\n",
        "texts = [doc.split() for doc in preprocessed_documents] # load text for NPMI\n",
        "\n",
        "npmi = CoherenceNPMI(texts=texts, topics=ctm.get_topic_lists(50))\n",
        "npmi_100 = CoherenceNPMI(texts=texts, topics=ctm_100.get_topic_lists(100))\n",
        "print(npmi.score())\n",
        "print(npmi_100.score())\n",
        "\n",
        "zeroshotNPMI = [npmi.score(), npmi_100.score()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1fNkV1sVJXh"
      },
      "source": [
        "**M2. Training Neural-ProdLDA**\n",
        "\n",
        "We use the implementation made available by [Carrow (2018)](https://github.com/estebandito22/PyTorchAVITM/blob/master/README.md).\n",
        "\n",
        "**Model Training Instructions**\n",
        "\n",
        "* Epochs = 100\n",
        "* ADAM optimizer -> learning rate = 2e-3. \n",
        "* The inference network is composed of a single hidden layer and 100-dimension of softplus units. \n",
        "* The priors over the topic and\n",
        "document distributions are **learnable parameters**.\n",
        "* Momentum = 0.99, learning rate = 0.002, and we apply 20% of drop-out to the hidden document representation. \n",
        "* Batch size = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yYO3ARJWTgg"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "!git clone https://github.com/estebandito22/PyTorchAVITM # COMMENT AFTER RUNNING ONCE\n",
        "!python /content/PyTorchAVITM/setup.py build\n",
        "!python /content/PyTorchAVITM/setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "sys.path.insert(1, \"/content/PyTorchAVITM\")\n",
        "from pytorchavitm import AVITM\n",
        "from pytorchavitm.datasets import BOWDataset\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "Yfu4LQJMf-gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Dataset\n",
        "train_data = BOWDataset(tp.id2token,training_dataset.X_bow.todense())\n",
        "\n",
        "cv = CountVectorizer(input = 'content')\n",
        "train_bow = cv.fit_transform(preprocessed_documents)\n",
        "train_bow = train_bow.toarray()\n",
        "\n",
        "idx2token = cv.get_feature_names()\n",
        "input_size = len(idx2token)\n",
        "\n",
        "train_data = BOWDataset(train_bow, idx2token)"
      ],
      "metadata": {
        "id": "MtDDvDwGnx2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Neural ProdLDA models\n",
        "avitm = AVITM(input_size=len(tp.vocab), n_components = 50, model_type='prodLDA',hidden_sizes=(100,100)\n",
        "                ,activation='softplus', dropout=0.2, learn_priors=True, \n",
        "              batch_size=200, lr=2e-3, momentum=0.99, solver='adam', num_epochs=100, reduce_on_plateau=False)\n",
        "\n",
        "avitm_100 = AVITM(input_size=len(tp.vocab), n_components = 100, model_type='prodLDA',hidden_sizes=(100,100)\n",
        "                ,activation='softplus', dropout=0.2, learn_priors=True, \n",
        "              batch_size=200, lr=2e-3, momentum=0.99, solver='adam', num_epochs=100, reduce_on_plateau=False)\n",
        "\n",
        "\n",
        "avitm.fit(train_data, save_dir=\"./\")\n",
        "avitm_100.fit(train_data, save_dir=\"./\")\n",
        "\n",
        "# NPMI Scores for t = 50 and t = 100\n",
        "npmi_avitm = CoherenceNPMI(topics = list(avitm.get_topics(50).values()), texts = texts).score()\n",
        "npmi_avitm_100 = CoherenceNPMI(topics = list(avitm_100.get_topics(100).values()), texts = texts).score()\n",
        "avitmNPMI = [npmi_avitm, npmi_avitm_100]\n",
        "print(avitmNPMI)"
      ],
      "metadata": {
        "id": "UzJwWBIzwHI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C2-splCWiHC"
      },
      "source": [
        "**M3. Training LDA**\n",
        "\n",
        "We use [Gensim’s](https://radimrehurek.com/gensim/models/ldamodel.html) implementation of this model.\n",
        "\n",
        "**Model Training Instructions**\n",
        "\n",
        "The hyper-parameters alpha and beta, controlling the document-topic and word-topic distribution respectively, are estimated from the data during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRtCl4zYW6qd"
      },
      "outputs": [],
      "source": [
        "# Train LDA models\n",
        "from typing import Dict\n",
        "from pprint import pprint\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models.ldamulticore import LdaModel\n",
        "\n",
        "# Create a corpus from a list of texts\n",
        "train_dict = Dictionary([text.split() for text in preprocessed_documents])\n",
        "train_corpus = [train_dict.doc2bow(text.split()) for text in preprocessed_documents]\n",
        "\n",
        "# Fit LDA models on the corpus\n",
        "lda = LdaModel(train_corpus, num_topics=50, passes = 30,\n",
        "               id2word=train_dict)\n",
        "\n",
        "lda_100 = LdaModel(train_corpus, num_topics=100, passes = 30,\n",
        "               id2word=train_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pprint(lda.print_topics())\n",
        "coherence_model_lda = CoherenceModel(model=lda, texts=texts, dictionary=train_dict, coherence='c_npmi')\n",
        "npmi_lda = coherence_model_lda.get_coherence()\n",
        "\n",
        "npmi_lda_100 = CoherenceModel(model=lda_100, texts=texts, dictionary=train_dict, coherence='c_npmi')\n",
        "print('\\nCoherence Score for 50: ', npmi_lda)\n",
        "print('\\nCoherence Score for 100: ', npmi_lda_100.get_coherence())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT3o-vWSvMXt",
        "outputId": "312c5f35-1b7e-46aa-b321-312bf03e6e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score for 50:  -0.07140085349638366\n",
            "\n",
            "Coherence Score for 100:  -0.1742381019805529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_25 = LdaModel(train_corpus, num_topics=50, passes = 30,\n",
        "               id2word=train_dict)\n",
        "\n",
        "coherence_model_lda = CoherenceModel(model=lda_25, texts=texts, dictionary=train_dict, coherence='c_npmi')\n",
        "coherence_model_lda.get_coherence()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u04f2Ns4Y59k",
        "outputId": "d0007cfc-b4f4-4d8c-b449-83f0f6e91eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.06021969745287585"
            ]
          },
          "metadata": {},
          "execution_count": 600
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_npmi =[npmi_lda, npmi_lda_100.get_coherence()]"
      ],
      "metadata": {
        "id": "LQ2xp_tpmzXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gAxAlpbXhZL"
      },
      "source": [
        "**M4. Training Combined TM**\n",
        "CTMs work better when the size of the bag of words has been restricted to a number of terms that does not go over 2000 elements. This is because we have a neural model that reconstructs the input bag of word, Moreover, in CombinedTM we project the contextualized embedding to the vocab space, the bigger the vocab the more parameters you get, with the training being more difficult and prone to bad fitting. \n",
        "\n",
        "**Model Training Instructions**\n",
        "\n",
        "* Epochs = 100\n",
        "* ADAM optimizer\n",
        "* Hyperparameters are the same used for Neural-ProdLDA with the difference that we also use SBERT features in combination with the BoW.\n",
        "* We take the SBERT embeddings, apply a (learnable) function/dense layer R^512 → R^|V|and concatenate the representation to the BoW. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W32pxJeCZk0h"
      },
      "outputs": [],
      "source": [
        "# Train CombinedTM for 50 and 100 topics\n",
        "from contextualized_topic_models.models.ctm import CombinedTM\n",
        "from contextualized_topic_models.utils.data_preparation import bert_embeddings_from_file\n",
        "\n",
        "# Fit CombinedTM models\n",
        "comtm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, batch_size=200, n_components=50)\n",
        "comtm_100 = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, batch_size = 200, n_components=100)\n",
        "#comtm.get_topic_lists(5)\n",
        "#comtm_100.get_topic_lists(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comtm.fit(training_dataset, save_dir = \"./\") # run the model\n",
        "comtm_100.fit(training_dataset, save_dir = \"./\") # run the model"
      ],
      "metadata": {
        "id": "oIgfvl7ujbn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get NPMI Coherence\n",
        "from contextualized_topic_models.evaluation.measures import CoherenceNPMI\n",
        "texts = [doc.split() for doc in preprocessed_documents] # load text for NPMI\n",
        "\n",
        "npmi_comtm = CoherenceNPMI(texts=texts, topics=ctm.get_topic_lists(50))\n",
        "npmi_comtm_100 = CoherenceNPMI(texts=texts, topics=ctm_100.get_topic_lists(100))\n",
        "print(npmi_comtm.score())\n",
        "print(npmi_comtm_100.score())\n",
        "\n",
        "combinedNPMI = [npmi_comtm.score(), npmi_comtm_100.score()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrqkHiOZMHr8",
        "outputId": "37edd7e5-5c96-4d07-e054-79f302714f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16294250186748438\n",
            "0.1477697544158918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM_N1a9SdowT"
      },
      "source": [
        "# Zero-shot Cross-Lingual Topic Modeling\n",
        "> Can the conxtextualized TM tackle zero-shot cross-lingual topic modeling?\n",
        "\n",
        "The second dataset (W2) contains 100,000 English documents. We use 99,700 documents as training and consider the remaining 300 documents as the test set. We collect the 300 respective instances in Portuguese, Italian, French, and German.\n",
        "\n",
        "First, we use SBERT to generate multilingual embeddings as the input of the model. Then we evaluate multilingual topic predictions on the multilingual abstracts in W2."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the contextualized topic model library\n",
        "%%capture\n",
        "!pip install contextualized-topic-models==2.2.0\n",
        "\n",
        "# Imports\n",
        "from contextualized_topic_models.models.ctm import ZeroShotTM\n",
        "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
        "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessing\n",
        "import nltk\n",
        "import pickle\n",
        "import numpy as np\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "pL_rO2YH1jhf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download W2 files for training and testing (given by authors)\n",
        "!curl -L \"https://drive.google.com/u/0/uc?id=1Mlhi5LUWxo7RqCOUvJuDzKZe4GauinoO&export=download\" -o dbpedia_train_unprep.txt\n",
        "!curl -L \"https://drive.google.com/u/0/uc?id=1HY-hi_DmoL4FYNTmlvUYgYL9x-yzroj3&export=download\" -o test_set"
      ],
      "metadata": {
        "id": "YGpvgsDOZN80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241a5e17-a001-438c-fe19-c59938720a4a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
            "100 77.0M  100 77.0M    0     0  16.9M      0  0:00:04  0:00:04 --:--:--  128M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100  763k  100  763k    0     0   408k      0  0:00:01  0:00:01 --:--:--  408k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "**Building Training Dataset (W2)**"
      ],
      "metadata": {
        "id": "km1wNJWNiYBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "puBg-Ma4eQNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fae7bc2-4e2a-4d16-9575-cf718fdb84d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Raw files (given by authors)\n",
        "train_file = \"dbpedia_train_unprep.txt\" # 100K english abstracts\n",
        "test_file = \"test_set\" # 300 comparable documents in it, fr, pt, de, en\n",
        "\n",
        "# Get Test File\n",
        "with open(test_file, \"rb\") as filino:\n",
        "  w2_test = pickle.load(filino)\n",
        "filino.close()\n",
        "\n",
        "# Extract multilingual test files (indices given by authors)\n",
        "italian_documents = [w2_test[i][0] for i in range(len(w2_test))]\n",
        "french_documents = [w2_test[i][1] for i in range(len(w2_test))]\n",
        "portugese_documents = [w2_test[i][2] for i in range(len(w2_test))]\n",
        "german_documents = [w2_test[i][3] for i in range(len(w2_test))]\n",
        "english_documents = [w2_test[i][4] for i in range(len(w2_test))] \n",
        "\n",
        "# Remove english documents from train file to get remaining 99,700 abstracts for training\n",
        "w2_train = list (set(open(train_file, encoding=\"utf-8\").readlines()) - set (english_documents))[:99700]\n",
        "\n",
        "# Preprocessing train set\n",
        "nltk.download('stopwords')\n",
        "documents = [line.strip() for line in w2_train]\n",
        "sp = WhiteSpacePreprocessing(documents, stopwords_language='english')\n",
        "preprocessed_documents, unpreprocessed_corpus, vocab = sp.preprocess()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Models"
      ],
      "metadata": {
        "id": "n_oNJ4cRtLLN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB_0IrzCdZp4"
      },
      "outputs": [],
      "source": [
        "# Load multilingual embeddings from SBERT\n",
        "tp = TopicModelDataPreparation(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "\n",
        "# Fit to build training dataset\n",
        "training_dataset = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train zeroshotTM with english abstracts with t = 25\n",
        "z_ctm_25 = ZeroShotTM(bow_size=len(tp.vocab), n_components = 25, contextual_size=768, num_epochs=100)\n",
        "z_ctm_25.fit(training_dataset, save_dir=\"./\") # run the model"
      ],
      "metadata": {
        "id": "PsvyFEtTwlM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train zeroshotTM with english abstracts with t = 50\n",
        "z_ctm_50 = ZeroShotTM(bow_size=len(tp.vocab), n_components = 50,contextual_size=768, num_epochs=100)\n",
        "z_ctm_50.fit(training_dataset, save_dir=\"./\") # run the model"
      ],
      "metadata": {
        "id": "EkzX_ZAB2k03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions and Evaluation\n",
        "**Unseen Multilingual  Corpora Predictions**"
      ],
      "metadata": {
        "id": "ID4xeEywiyE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download 25 and 50 topic models\n",
        "# !mkdir \"contextualized_topic_model_nc_25_tpm_0_tpv_096_hs_prodLDA_ac_do_softplus_lr_02_mo_0002_rp_099\"\n",
        "# !curl -L \"https://drive.google.com/u/0/uc?id=1dA4szvg8aIJtXz0CrVpD7HeKEeV-vo6R&export=download\" -o contextualized_topic_model_nc_25_tpm_0_tpv_096_hs_prodLDA_ac_do_softplus_lr_02_mo_0002_rp_099/epoch_99.pth\n",
        "# !cd ..\n",
        "# # !mkdir \"contextualized_topic_model_nc_50_tpm_0.0_tpv_0.98_hs_prodLDA_ac_(100, 100)_do_softplus_lr_0.2_mo_0.002_rp_0.99\"\n",
        "# # !curl -L \"https://drive.google.com/u/0/uc?id=1HY-hi_DmoL4FYNTmlvUYgYL9x-yzroj3&export=download\" -o ccontextualized_topic_model_nc_50_tpm_0.0_tpv_0.98_hs_prodLDA_ac_do_softplus_lr_0.2_mo_0.002_rp_0.99/epoch_99.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIia5yl2UXfU",
        "outputId": "f1ff5e3b-e519-4d37-da67-147a00af8f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  2214    0  2214    0     0   6750      0 --:--:-- --:--:-- --:--:--  6750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load model for 25 topics\n",
        "# z_ctm_25 = ZeroShotTM(bow_size=len(tp.vocab), n_components = 25, contextual_size = 768, num_epochs = 100)\n",
        "z_ctm_25.load(model_dir = \"/content/contextualized_topic_model_nc_25_tpm_0.0_tpv_0.96_hs_prodLDA_ac_(100, 100)_do_softplus_lr_0.2_mo_0.002_rp_0.99\", epoch = 99)"
      ],
      "metadata": {
        "id": "qQZXUZxPPueQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load model for 50 topics\n",
        "# z_ctm_50 = ZeroShotTM(bow_size=len(tp.vocab), n_components = 25, contextual_size = 768, num_epochs = 100)\n",
        "# z_ctm_50.load(model_dir = \"/content/contextualized_topic_model_nc_50_tpm_0.0_tpv_0.98_hs_prodLDA_ac_(100, 100)_do_softplus_lr_0.2_mo_0.002_rp_0.99\", \n",
        "#                     epoch = 99)"
      ],
      "metadata": {
        "id": "8BCglRLVXvKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert test files into test datasets\n",
        "it_testset = tp.transform(italian_documents)\n",
        "fr_testset = tp.transform(french_documents)\n",
        "de_testset = tp.transform(german_documents)\n",
        "pt_testset = tp.transform(portugese_documents)\n",
        "en_testset = tp.transform(english_documents)"
      ],
      "metadata": {
        "id": "IcyhlPNu3CiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 25 TOPIC PREDICTIONS ### \n",
        "it_topics_predictions = z_ctm_25.get_thetas(it_testset, n_samples=100) # get all the topic predictions\n",
        "fr_topics_predictions = z_ctm_25.get_thetas(fr_testset, n_samples=100) # get all the topic predictions\n",
        "de_topics_predictions = z_ctm_25.get_thetas(de_testset, n_samples=100) # get all the topic predictions\n",
        "pt_topics_predictions = z_ctm_25.get_thetas(pt_testset, n_samples=100) # get all the topic predictions\n",
        "en_topics_predictions = z_ctm_25.get_thetas(en_testset, n_samples=100) # get all the topic predictions\n",
        "\n",
        "topics_25 = [it_topics_predictions, fr_topics_predictions, \n",
        "             pt_topics_predictions, de_topics_predictions,\n",
        "             en_topics_predictions]"
      ],
      "metadata": {
        "id": "gy-tDYkpcDcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c7345f-7621-422d-bb71-e4c7156e4a51"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: [100/100]: : 100it [00:56,  1.77it/s]\n",
            "Sampling: [100/100]: : 100it [00:54,  1.82it/s]\n",
            "Sampling: [100/100]: : 100it [00:55,  1.79it/s]\n",
            "Sampling: [100/100]: : 100it [00:55,  1.81it/s]\n",
            "Sampling: [100/100]: : 100it [00:55,  1.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics_25[4]\n",
        "topics_25[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqU0jMfWPXbY",
        "outputId": "a34cdbea-aa23-4f59-f891-45162ef96458"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03950265, 0.1565703 , 0.02988122, ..., 0.03332205, 0.02045516,\n",
              "        0.02141155],\n",
              "       [0.03132896, 0.01871674, 0.02781799, ..., 0.03004164, 0.02020359,\n",
              "        0.01966489],\n",
              "       [0.03622307, 0.02629677, 0.01945086, ..., 0.02466495, 0.01999504,\n",
              "        0.01880061],\n",
              "       ...,\n",
              "       [0.02127323, 0.01354207, 0.03119404, ..., 0.02215813, 0.02936685,\n",
              "        0.01039033],\n",
              "       [0.02338544, 0.02284519, 0.03164743, ..., 0.01572657, 0.03061562,\n",
              "        0.00745121],\n",
              "       [0.05410563, 0.024912  , 0.08447234, ..., 0.0271306 , 0.01712496,\n",
              "        0.01671226]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 50 TOPIC PREDICTIONS ### \n",
        "it_topics_predictions = z_ctm_50.get_thetas(it_testset, n_samples=100) # get all the topic predictions\n",
        "fr_topics_predictions = z_ctm_50.get_thetas(fr_testset, n_samples=100) # get all the topic predictions\n",
        "de_topics_predictions = z_ctm_50.get_thetas(de_testset, n_samples=100) # get all the topic predictions\n",
        "pt_topics_predictions = z_ctm_50.get_thetas(pt_testset, n_samples=100) # get all the topic predictions\n",
        "en_topics_predictions = z_ctm_50.get_thetas(en_testset, n_samples=100) # get all the topic predictions\n",
        "\n",
        "topics_50 = [it_topics_predictions, fr_topics_predictions, \n",
        "             pt_topics_predictions, de_topics_predictions,\n",
        "             en_topics_predictions]"
      ],
      "metadata": {
        "id": "d5ZFFpd43v6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817e0414-6385-490e-e33e-5ff6db6173ee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: [100/100]: : 100it [01:38,  1.01it/s]\n",
            "Sampling: [100/100]: : 100it [01:38,  1.01it/s]\n",
            "Sampling: [100/100]: : 100it [01:40,  1.00s/it]\n",
            "Sampling: [100/100]: : 100it [01:39,  1.00it/s]\n",
            "Sampling: [100/100]: : 100it [01:40,  1.01s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantitative Evaluation**"
      ],
      "metadata": {
        "id": "1EyO4qpXm4Nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import metrics\n",
        "from contextualized_topic_models.evaluation.measures import Matches, KLDivergence, CentroidDistance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "PUHdC6ztmzr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bced55-6889-494f-cf5f-c3c9ac981a73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
            "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
            "  _deprecated()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJvWmhANeWea"
      },
      "source": [
        "1. **Matches**\n",
        "\n",
        "> Matches is the % of times the predicted topic for the non-English test document is the same as for the respective test document in English. The higher the scores, the better."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matches for 25 topics\n",
        "en_it_matches = Matches(topics_25[4], topics_25[0])\n",
        "en_fr_matches = Matches(topics_25[4], topics_25[1])\n",
        "en_pt_matches = Matches(topics_25[4], topics_25[2])\n",
        "en_de_matches = Matches(topics_25[4], topics_25[3])\n",
        "\n",
        "matches_25 = [en_it_matches.score(), en_fr_matches.score(), \n",
        "           en_pt_matches.score(), en_de_matches.score()]\n",
        "matches_25"
      ],
      "metadata": {
        "id": "aF2GPx1_5Mal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4d38f00-4112-4142-bfe8-d977785a6874"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.77, 0.7833333333333333, 0.75, 0.7533333333333333]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matches for 50 topics\n",
        "en_it_matches = Matches(topics_50[4], topics_50[0])\n",
        "en_fr_matches = Matches(topics_50[4], topics_50[1])\n",
        "en_pt_matches = Matches(topics_50[4], topics_50[2])\n",
        "en_de_matches = Matches(topics_50[4], topics_50[3])\n",
        "\n",
        "matches_50 = [en_it_matches.score(), en_fr_matches.score(), \n",
        "           en_pt_matches.score(), en_de_matches.score()]"
      ],
      "metadata": {
        "id": "WLw8Xkt5dElD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Distributional Similarity**\n",
        "> Compute the KL divergence between the predicted topic distribution on the test document and the same test document in English. Lower scores are better, indicating that the distributions do not differ by much."
      ],
      "metadata": {
        "id": "PysLdKoyZ-fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KL Divergence for 25 topics\n",
        "en_it_kl = KLDivergence(topics_25[4], topics_25[0])\n",
        "en_fr_kl = KLDivergence(topics_25[4], topics_25[1])\n",
        "en_pt_kl = KLDivergence(topics_25[4], topics_25[2])\n",
        "en_de_kl = KLDivergence(topics_25[4], topics_25[3])\n",
        "\n",
        "kl_divergence_25 = [en_it_kl.score(), en_fr_kl.score(), \n",
        "           en_de_kl.score(), en_pt_kl.score()]\n",
        "           \n",
        "kl_divergence_25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc8TYrOCnUt6",
        "outputId": "e223ad63-b424-411b-a1b9-90f66d3056cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12937350917783688,\n",
              " 0.13802749811641576,\n",
              " 0.1472539906039054,\n",
              " 0.11945237810821654]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KL Divergence for 50 topics\n",
        "en_it_kl = KLDivergence(topics_50[4], topics_50[0])\n",
        "en_fr_kl = KLDivergence(topics_50[4], topics_50[1])\n",
        "en_pt_kl = KLDivergence(topics_50[4], topics_50[2])\n",
        "en_de_kl = KLDivergence(topics_50[4], topics_50[3])\n",
        "\n",
        "kl_divergence_50 = [en_it_kl.score(), en_fr_kl.score(), \n",
        "           en_de_kl.score(), en_pt_kl.score()]\n",
        "\n",
        "kl_divergence_50"
      ],
      "metadata": {
        "id": "OztmlUHK5M8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Centroid Embeddings**\n",
        "> To also account for similar but not exactly equal topic predictions, we compute the centroid embeddings of the 5 words describing the predicted topic for both English and non-English documents. Then we compute the cosine similarity between those two centroids (CD)."
      ],
      "metadata": {
        "id": "UzpXFJ0wZ5-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora.dictionary import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "from scipy.spatial.distance import cosine\n",
        "import abc\n",
        "\n",
        "class CD(CentroidDistance):\n",
        "    \"\"\"Override author's function to upgrade compatibility with Gensim 4.0.0.\n",
        "    See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4.\"\"\"\n",
        "\n",
        "    def get_centroid(self, word_list):\n",
        "        vector_list = []\n",
        "        for word in word_list:\n",
        "            if word in self.wv:   # changed from self.wv.vocab to self.wv as in Gensim 4.0.0\n",
        "                vector_list.append(self.wv.get_vector(word))\n",
        "        vec = sum(vector_list)\n",
        "        return vec / np.linalg.norm(vec)"
      ],
      "metadata": {
        "id": "AbXgKs-u5NyD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Centroid Embeddings for 25 topics\n",
        "cd_25 = []\n",
        "\n",
        "for i in range(4):\n",
        "  cd = CD(doc_distribution_original_language = topics_25[4], \n",
        "          doc_distribution_unseen_language = topics_25[i], \n",
        "          topics = z_ctm_25.get_topic_lists(25),\n",
        "          topk = 5)\n",
        "  \n",
        "  cd_25.append(cd.score())\n",
        "\n",
        "cd_25"
      ],
      "metadata": {
        "id": "CjnYIIng5MyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_25 = [matches_25, kl_divergence_25, cd_25]\n",
        "with open(\"metrics.txt\", 'wb') as F:\n",
        "  pickle.dump(metrics_25, F)"
      ],
      "metadata": {
        "id": "9xOqwsCSVAAG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Centroid Embeddings for 50 topics\n",
        "cd_50 = []\n",
        "\n",
        "for i in range(4):\n",
        "  cd = CD(doc_distribution_original_language = topics_50[4], \n",
        "          doc_distribution_unseen_language = topics_50[i], \n",
        "          topics = z_ctm_50.get_topic_lists(25),\n",
        "          topk = 5)\n",
        "  \n",
        "  cd_50.append(cd.score())\n",
        "  cd = 0\n",
        "\n",
        "cd_50"
      ],
      "metadata": {
        "id": "WXRBx6VjW-5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58bc4d54-47fe-49d5-f4f5-5e8be203db3b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7623366142809391,\n",
              " 0.7303878939151764,\n",
              " 0.7646546208610138,\n",
              " 0.7610922541220982]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {\"Mat25\": matches_25,\n",
        "           \"KL25\": kl_divergence_25, \n",
        "           \"CD25\": cd_25, \n",
        "           \"Mat50\": matches_50, \n",
        "           \"KL50\": kl_divergence_50,\n",
        "           \"CD50\": cd_50}\n",
        "with open(\"metrics.txt\", 'wb') as F:\n",
        "  pickle.dump(metrics, F)"
      ],
      "metadata": {
        "id": "obeCKsgJ9gf4"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nEYfwujnu5Wh"
      ],
      "name": "ZeroshotTM - Parent Paper Implementation",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}