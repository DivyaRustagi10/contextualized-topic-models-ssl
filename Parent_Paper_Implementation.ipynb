{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEYfwujnu5Wh"
      },
      "source": [
        "#To contextualize or to not contextualize?\n",
        "\n",
        "> Can we define a topic model that does not rely on the BoW input but instead uses contextual information?\n",
        "\n",
        "First, we want to check if ZeroShotTM maintains comparable performance to other topic models; if this is true, we can then explore its performance in\n",
        "a cross-lingual setting. Since we use only English text, in this setting we use English representations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3H5Cn_ftZzW"
      },
      "outputs": [],
      "source": [
        "# Install the contextualized topic model library\n",
        "%%capture\n",
        "!pip install contextualized-topic-models==2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vht2fQJ6uqvh"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyldavis\n",
        "!pip install wget\n",
        "!pip install head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOSAecV9wQGP"
      },
      "source": [
        "We replace the input BoW in Neural-ProdLDA\n",
        "with pre-trained multilingual representations from\n",
        "SBERT (Reimers and Gurevych, 2019), a recent and effective model for contextualized representations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdhn10XNwVL1"
      },
      "source": [
        "Indeed, ZeroShotTM\n",
        "is language-independent: given a contextualized\n",
        "representation of a new language as input,1\n",
        "it can\n",
        "predict the topic distribution of the document. The\n",
        "predicted topic descriptors, though, will be from\n",
        "the training language. Let us also notice that our\n",
        "method is agnostic about the choice of the neural\n",
        "topic model architecture (here, Neural-ProdLDA),\n",
        "as long as it extends a Variational Autoencoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnXnkp3TxGYy"
      },
      "source": [
        "# Data\n",
        "\n",
        "### Building Comparable Documents\n",
        "Datasets We use datasets collected from English\n",
        "Wikipedia abstracts from DBpedia. The first dataset (W1) contains 20,000 randomly sampled abstracts. The second dataset (W2) contains 100,000 English documents. \n",
        "\n",
        "We use 99,700 documents as\n",
        "training and consider the remaining 300 documents as the test set. We collect the 300 respective instances in Portuguese, Italian, French, and German.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRYo3hb4zUTf"
      },
      "source": [
        "### Building W1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ROk_X9zXH_",
        "outputId": "6b8f442f-175b-4f5b-8bd9-9e84b9d2b857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% [.........................................................] 6208417 / 6208417"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dbpedia_sample_abstract_20k_unprep (4).txt'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import wget\n",
        "wget.download(\"https://raw.githubusercontent.com/vinid/data/master/dbpedia_sample_abstract_20k_unprep.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP8KlaHlzkLa"
      },
      "outputs": [],
      "source": [
        "text_file = \"dbpedia_sample_abstract_20k_unprep.txt\" # EDIT THIS WITH THE FILE YOU UPLOAD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv6bBtGdzp0p"
      },
      "source": [
        "### Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erO2thoszs7P"
      },
      "outputs": [],
      "source": [
        "from contextualized_topic_models.models.ctm import ZeroShotTM\n",
        "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
        "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessing\n",
        "import nltk\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkbIsafEz6w3"
      },
      "source": [
        "### Preprocessing\n",
        "Why do we use the preprocessed text here? We need text without punctuation to build the bag of word. Also, we might want only to have the most frequent words inside the BoW. Too many words might not help."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQBKiAC_z_aj",
        "outputId": "a8fcf51c-0902-4e38-a10e-fa278827cbae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\divya_rustagi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "C:\\Users\\divya_rustagi\\anaconda3\\envs\\ds340w\\lib\\site-packages\\scikit_learn-1.0.2-py3.9-win-amd64.egg\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "documents = [line.strip() for line in open(text_file, encoding=\"utf-8\").readlines()]\n",
        "sp = WhiteSpacePreprocessing(documents, stopwords_language='english')\n",
        "preprocessed_documents, unpreprocessed_corpus, vocab = sp.preprocess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ25XIm60AL3",
        "outputId": "4216e2d6-d280-4498-d5dc-8f85a991dd5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mid peninsula highway proposed across peninsula canadian province ontario although highway connecting hamilton fort south international study published ministry',\n",
              " 'died march american photographer specialized photography operated studio silver spring maryland later lived florida magazine photographer year']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "preprocessed_documents[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnIptVxk0F4n"
      },
      "source": [
        "We don't discard the non-preprocessed texts, because we are going to use them as input for obtaining the contextualized document representations.\n",
        "\n",
        "Let's pass our files with preprocess and unpreprocessed data to our TopicModelDataPreparation object. This object takes care of creating the bag of words for you and of obtaining the contextualized BERT representations of documents. This operation allows us to create our training dataset.\n",
        "\n",
        "Note: Here we use the contextualized model \"distiluse-base-multilingual-cased\", because we need a multilingual model for performing cross-lingual predictions later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO-88XsA0G6m"
      },
      "outputs": [],
      "source": [
        "# Building W1\n",
        "tp = TopicModelDataPreparation(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "70ebf5098691413883d2ff2a11378ea0",
            "8a9627b0976a4772b10c45dde546ef3f",
            "7d572eaf4581466ca8827a960f09ea00",
            "c6e11dadfff94c4882a2fdd60bf2016d",
            "12b59f568c7d4d2681ac7777320f2e04",
            "2bd1e775cef945678d0b8edfefc38619",
            "8aa0ade568394b09aedbc47b0c7ba7ab",
            "1b623202a18843358f31c3d4976ac01d",
            "f15da367aabb4f459c87e0f463dbb709",
            "a584dc207b5b47fb92ac0aceb8a3524e",
            "c53560aed611476faff78deaf351bab3"
          ]
        },
        "id": "WfKQcrICxfb-",
        "outputId": "4c9bc481-9371-47d4-877d-1013f926c345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70ebf5098691413883d2ff2a11378ea0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(training_dataset, open('training_dataset.txt', 'wb'), pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "vHRFOkee8qAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKSz0NtT0KD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669ce191-c5ee-4bcd-ca17-de688bd502d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abbreviated',\n",
              " 'academic',\n",
              " 'academy',\n",
              " 'access',\n",
              " 'according',\n",
              " 'achieved',\n",
              " 'acquired',\n",
              " 'acre',\n",
              " 'acres',\n",
              " 'across']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "tp.vocab[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvN6JTLT0PMj"
      },
      "source": [
        "## M1. Training Zero-Shot Contextualized Topic Model\n",
        "\n",
        "Finally, we can fit our new topic model. We will ask the model to find 50 topics in our collection (n_component parameter of the CTM object)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGDIur9O0Qa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780e69ba-f6d8-45ed-ff63-a0660c386f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: [100/100]\t Seen Samples: [2000000/2000000]\tTrain Loss: 151.11905070800782\tTime: 0:00:17.208018: : 100it [29:07, 17.48s/it]\n"
          ]
        }
      ],
      "source": [
        "#with open('training_dataset.obj', \"rb\") as fr:\n",
        "#  training_dataset = pickle.load(fr)\n",
        "type(training_dataset)\n",
        "\n",
        "# 100 topics over 100 runs\n",
        "ctm = ZeroShotTM(bow_size=len(tp.vocab), contextual_size=768, n_components=100, num_epochs=100)\n",
        "ctm.fit(training_dataset) # run the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucgzwNqP0YA6"
      },
      "source": [
        "**1.1. Get Topics**\n",
        "\n",
        "After training, now it is the time to look at our topics: we can use the\n",
        "\n",
        "\n",
        "```\n",
        "get_topic_lists\n",
        "```\n",
        "function to get the topics. It also accepts a parameter that allows you to select how many words you want to see for each topic.\n",
        "\n",
        "If you look at the topics, you will see that they all make sense and are representative of a collection of documents that comes from Wikipedia (general knowledge). Notice that the topics are in English, because we trained the model on English documents."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctm.get_topic_lists(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrYUpAUhRohf",
        "outputId": "95078be6-0b44-418a-85af-db93b14110f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['published', 'newspaper', 'magazine', 'daily', 'publishing'],\n",
              " ['states', 'united', 'community', 'located', 'county'],\n",
              " ['game', 'video', 'developed', 'japan', 'games'],\n",
              " ['australian', 'south', 'west', 'east', 'within'],\n",
              " ['play', 'directed', 'written', 'silent', 'novel'],\n",
              " ['university', 'college', 'engineering', 'technology', 'institute'],\n",
              " ['war', 'battle', 'british', 'royal', 'fought'],\n",
              " ['population', 'census', 'town', 'community', 'civil'],\n",
              " ['island', 'river', 'lake', 'park', 'australia'],\n",
              " ['member', 'john', 'british', 'canada', 'politician'],\n",
              " ['information', 'services', 'service', 'internet', 'business'],\n",
              " ['russian', 'iron', 'cross', 'knight', 'summer'],\n",
              " ['station', 'class', 'line', 'railway', 'power'],\n",
              " ['manufactured', 'company', 'design', 'manufacturer', 'production'],\n",
              " ['languages', 'spoken', 'language', 'term', 'people'],\n",
              " ['church', 'roman', 'catholic', 'saint', 'latin'],\n",
              " ['street', 'centre', 'mall', 'building', 'shopping'],\n",
              " ['government', 'act', 'responsible', 'department', 'law'],\n",
              " ['district', 'iran', 'central', 'persian', 'rural'],\n",
              " ['journal', 'society', 'research', 'established', 'association'],\n",
              " ['high', 'university', 'school', 'college', 'year'],\n",
              " ['name', 'spanish', 'uses', 'born', 'brazilian'],\n",
              " ['air', 'force', 'unit', 'united', 'states'],\n",
              " ['professor', 'university', 'research', 'president', 'law'],\n",
              " ['india', 'village', 'situated', 'civil', 'small'],\n",
              " ['team', 'head', 'football', 'represented', 'coach'],\n",
              " ['states', 'united', 'american', 'served', 'war'],\n",
              " ['played', 'canadian', 'football', 'professional', 'former'],\n",
              " ['brown', 'described', 'white', 'mm', 'found'],\n",
              " ['division', 'men', 'conference', 'basketball', 'tournament'],\n",
              " ['star', 'planet', 'thus', 'belongs', 'discovered'],\n",
              " ['congo', 'family', 'natural', 'found', 'guinea'],\n",
              " ['usually', 'water', 'often', 'used', 'material'],\n",
              " ['russia', 'square', 'republic', 'administrative', 'oblast'],\n",
              " ['greek', 'al', 'bc', 'king', 'egypt'],\n",
              " ['common', 'native', 'plant', 'eastern', 'name'],\n",
              " ['building', 'house', 'museum', 'built', 'street'],\n",
              " ['de', 'french', 'princess', 'daughter', 'paris'],\n",
              " ['club', 'stadium', 'based', 'league', 'home'],\n",
              " ['mobile', 'software', 'platform', 'web', 'allows'],\n",
              " ['game', 'released', 'japanese', 'album', 'published'],\n",
              " ['best', 'known', 'role', 'actor', 'stage'],\n",
              " ['studied', 'ordained', 'bishop', 'priest', 'became'],\n",
              " ['series', 'book', 'characters', 'character', 'written'],\n",
              " ['house', 'built', 'wood', 'story', 'style'],\n",
              " ['work', 'writer', 'poet', 'book', 'author'],\n",
              " ['within', 'south', 'approximately', 'north', 'east'],\n",
              " ['system', 'systems', 'computer', 'standard', 'developed'],\n",
              " ['list', 'national', 'complete', 'places', 'intended'],\n",
              " ['political', 'party', 'union', 'government', 'republic'],\n",
              " ['war', 'world', 'ii', 'german', 'division'],\n",
              " ['american', 'york', 'director', 'new', 'best'],\n",
              " ['member', 'party', 'norwegian', 'politician', 'served'],\n",
              " ['company', 'largest', 'group', 'bank', 'founded'],\n",
              " ['term', 'often', 'refers', 'used', 'usually'],\n",
              " ['album', 'released', 'studio', 'recorded', 'records'],\n",
              " ['award', 'indian', 'festival', 'film', 'best'],\n",
              " ['major', 'league', 'baseball', 'season', 'franchise'],\n",
              " ['association', 'women', 'international', 'sports', 'club'],\n",
              " ['music', 'festival', 'orchestra', 'rock', 'radio'],\n",
              " ['chinese', 'china', 'line', 'pinyin', 'railway'],\n",
              " ['route', 'long', 'line', 'highway', 'state'],\n",
              " ['de', 'reserve', 'mexico', 'largest', 'la'],\n",
              " ['produced', 'show', 'indian', 'stars', 'television'],\n",
              " ['member', 'born', 'served', 'politician', 'wisconsin'],\n",
              " ['school', 'high', 'education', 'college', 'secondary'],\n",
              " ['school', 'church', 'high', 'st', 'christian'],\n",
              " ['american', 'former', 'played', 'born', 'major'],\n",
              " ['cup', 'final', 'competition', 'championship', 'football'],\n",
              " ['kilometres', 'approximately', 'mi', 'lies', 'italian'],\n",
              " ['england', 'road', 'london', 'west', 'railway'],\n",
              " ['high', 'school', 'county', 'public', 'district'],\n",
              " ['chinese', 'china', 'iran', 'also', 'pinyin'],\n",
              " ['german', 'within', 'germany', 'polish', 'poland'],\n",
              " ['hospital', 'center', 'located', 'city', 'centre'],\n",
              " ['state', 'park', 'route', 'river', 'sr'],\n",
              " ['channel', 'radio', 'news', 'owned', 'television'],\n",
              " ['metres', 'summer', 'competed', 'world', 'gold'],\n",
              " ['player', 'hockey', 'ice', 'canadian', 'professional'],\n",
              " ['space', 'chemical', 'mathematics', 'thus', 'specifically'],\n",
              " ['known', 'artist', 'music', 'musician', 'born'],\n",
              " ['right', 'first', 'made', 'english', 'medium'],\n",
              " ['season', 'final', 'first', 'second', 'began'],\n",
              " ['containing', 'genus', 'following', 'placed', 'contains'],\n",
              " ['john', 'england', 'st', 'english', 'sir'],\n",
              " ['lead', 'stars', 'produced', 'released', 'band'],\n",
              " ['named', 'point', 'land', 'peak', 'expedition'],\n",
              " ['island', 'islands', 'australia', 'coast', 'sea'],\n",
              " ['al', 'russian', 'general', 'served', 'august'],\n",
              " ['airport', 'iata', 'icao', 'international', 'scheduled'],\n",
              " ['australian', 'zealand', 'union', 'rugby', 'played'],\n",
              " ['french', 'director', 'paris', 'films', 'best'],\n",
              " ['held', 'figure', 'skating', 'event', 'world'],\n",
              " ['race', 'racing', 'car', 'grand', 'tour'],\n",
              " ['band', 'formed', 'rock', 'group', 'records'],\n",
              " ['held', 'presidential', 'elections', 'states', 'election'],\n",
              " ['part', 'town', 'pronounced', 'slovenia', 'settlement'],\n",
              " ['york', 'new', 'united', 'states', 'city'],\n",
              " ['created', 'council', 'members', 'electoral', 'constituency'],\n",
              " ['region', 'italian', 'municipality', 'population', 'area']]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2. Get Topic Prediction**"
      ],
      "metadata": {
        "id": "p2APr5SnQlp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics_predictions = ctm.get_thetas(training_dataset, n_samples=30) # get all the topic predictions\n",
        "#topics_predictions = ctm.get_thetas(training_dataset, n_samples=100) # get all the topic predictions"
      ],
      "metadata": {
        "id": "A1SjT8aXQn1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5ac0bb-047e-4dab-bba6-9854dcf28fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: [30/30]: : 30it [07:47, 15.57s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_documents[0] # see the text of our preprocessed document"
      ],
      "metadata": {
        "id": "NlmsLM27QqUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "953b4c97-ae0b-4155-8e7b-18c79dce2641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mid peninsula highway proposed across peninsula canadian province ontario although highway connecting hamilton fort south international study published ministry'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "topic_number = np.argmax(topics_predictions[0]) # get the topic id of the first document"
      ],
      "metadata": {
        "id": "qDmShhDYQsHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctm.get_topic_lists(5)[topic_number] #and the topic should be about natural location related things"
      ],
      "metadata": {
        "id": "WsbwFDx9QtYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ffc372-bb62-4944-ddd1-1d4cb226b626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['route', 'long', 'line', 'highway', 'state']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(preprocessed_documents, open('preprocessed_documents.txt', 'wb'), pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "rDCMxHFzun31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get NPMI Coherence\n",
        "from contextualized_topic_models.evaluation.measures import CoherenceNPMI\n",
        "\n",
        "with open('preprocessed_documents.txt', \"rb\") as fr:\n",
        "  fr = pickle.load(fr)\n",
        "  texts = [doc.split() for doc in fr] # load text for NPMI\n",
        "  npmi = CoherenceNPMI(texts=texts, topics=ctm.get_topic_lists(50))\n",
        "  npmi_100 = CoherenceNPMI(texts=texts, topics=ctm.get_topic_lists(100))\n",
        "  print(npmi.score())\n",
        "  print(npmi_100.score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTobj2_LtNWw",
        "outputId": "2f412f18-ac87-470d-df30-85da85539fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.16451367383661852\n",
            "0.16451367383661852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## M2. Training Neural-ProdLDA\n",
        "\n",
        "We use the implementation made available by [Carrow (2018)](https://github.com/estebandito22/PyTorchAVITM/blob/master/README.md).\n",
        "\n",
        "**Model Training Instructions**\n",
        "\n",
        "* Epochs = 100\n",
        "* ADAM optimizer -> learning rate = 2e-3. \n",
        "* The inference network is composed of a single hidden layer and 100-dimension of softplus units. \n",
        "* The priors over the topic and\n",
        "document distributions are **learnable parameters**.\n",
        "* Momentum = 0.99, learning rate = 0.002, and we apply 20% of drop-out to the hidden document representation. \n",
        "* Batch size = 200"
      ],
      "metadata": {
        "id": "s1fNkV1sVJXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yYO3ARJWTgg",
        "outputId": "596479f7-ad8b-4732-e23a-f24139a18eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### M3. Training LDA\n",
        "\n",
        "We use [Gensim’s](https://radimrehurek.com/gensim/models/ldamodel.html) implementation of this model.\n",
        "\n",
        "**Model Training Instructions**\n",
        "\n",
        "The hyper-parameters alpha and beta, controlling the document-topic and word-topic distribution respectively, are estimated from the data during training."
      ],
      "metadata": {
        "id": "2C2-splCWiHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oRtCl4zYW6qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## M4. Training Combined TM\n",
        "CTMs work better when the size of the bag of words has been restricted to a number of terms that does not go over 2000 elements. This is because we have a neural model that reconstructs the input bag of word, Moreover, in CombinedTM we project the contextualized embedding to the vocab space, the bigger the vocab the more parameters you get, with the training being more difficult and prone to bad fitting. \n",
        "\n",
        "**Model Training Instructions**\n",
        "\n",
        "* Epochs = 100\n",
        "* ADAM optimizer\n",
        "* Hyperparameters are the same used for Neural-ProdLDA with the difference that we also use SBERT features in combination with the BoW.\n",
        "* We take the SBERT embeddings, apply a (learnable) function/dense layer R^512 → R^|V|and concatenate the representation to the BoW. "
      ],
      "metadata": {
        "id": "9gAxAlpbXhZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from contextualized_topic_models.models.ctm import CombinedTM"
      ],
      "metadata": {
        "id": "Do2zUvzuYwos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, n_components=20, num_epochs=10)\n",
        "ctm.fit(training_dataset) # run the model"
      ],
      "metadata": {
        "id": "fcffbEGQZDdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctm.get_topic_lists(5)"
      ],
      "metadata": {
        "id": "1J0rKXmJZHMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Topic Predictions"
      ],
      "metadata": {
        "id": "WBt_PbMxZVmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics_predictions = ctm.get_thetas(training_dataset, n_samples=5) # get all the topic predictions"
      ],
      "metadata": {
        "id": "qp0-g5OBZKzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "topic_number = np.argmax(topics_predictions[0]) # get the topic id of the first document"
      ],
      "metadata": {
        "id": "9nZJcSwwZbCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctm.get_topic_lists(5)[18]\n",
        "ctm.get_topic_lists(5)[topic_number] #and the topic should be about natural location related things"
      ],
      "metadata": {
        "id": "X1npEgs6Zdov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving Models"
      ],
      "metadata": {
        "id": "IEkGauIAZiGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ctm.save(models_dir=\"./\")\n",
        "# let's remove the trained model\n",
        "del ctm\n",
        "\n",
        "ctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, num_epochs=100, n_components=50)\n",
        "\n",
        "ctm.load(\"/content/contextualized_topic_model_nc_50_tpm_0.0_tpv_0.98_hs_prodLDA_ac_(100, 100)_do_softplus_lr_0.2_mo_0.002_rp_0.99\",\n",
        "                                                                                                      epoch=19)\n",
        "ctm.get_topic_lists(5)"
      ],
      "metadata": {
        "id": "W32pxJeCZk0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-shot Cross-Lingual Topic Modeling\n",
        "> Can the conxtextualized TM tackle zero-shot cross-lingual topic modeling?\n",
        "\n",
        "ZeroShotTM can be used for zero-shot cross-lingual topic modeling. \n",
        "\n",
        "First, we use SBERT to generate multilingual embeddings as the input of the model. Then we evaluate multilingual topic predictions on the multilingual abstracts in W2."
      ],
      "metadata": {
        "id": "EM_N1a9SdowT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "puBg-Ma4eQNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantitative Evaluation\n",
        "Metrics\n",
        "1. **Matches**:\n",
        "% of times the predicted topic for the non-English test document is the same as for the respective test document in English. The higher the scores, the better.\n",
        "\n",
        "2. **Centroid Embeddings**: To also account for similar but not exactly equal\n",
        "topic predictions, we compute the centroid embeddings of the 5 words describing the predicted topic for both English and non-English documents. Then we compute the cosine similarity between those two centroids (CD).\n",
        "\n",
        "3. **Distributional Similarity**: Compute the KL divergence between the predicted topic distribution on the test document\n",
        "and the same test document in English. Lower scores are better, indicating that the distributions do not differ by much.\n",
        "\n",
        "> /Desktop/ctm_implementation/contextualized-topic-models/contextualized_topic_models/evaluation/measures.py\n",
        "\n"
      ],
      "metadata": {
        "id": "rJvWmhANeWea"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Parent Paper Implementation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70ebf5098691413883d2ff2a11378ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a9627b0976a4772b10c45dde546ef3f",
              "IPY_MODEL_7d572eaf4581466ca8827a960f09ea00",
              "IPY_MODEL_c6e11dadfff94c4882a2fdd60bf2016d"
            ],
            "layout": "IPY_MODEL_12b59f568c7d4d2681ac7777320f2e04"
          }
        },
        "8a9627b0976a4772b10c45dde546ef3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd1e775cef945678d0b8edfefc38619",
            "placeholder": "​",
            "style": "IPY_MODEL_8aa0ade568394b09aedbc47b0c7ba7ab",
            "value": "Batches: 100%"
          }
        },
        "7d572eaf4581466ca8827a960f09ea00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b623202a18843358f31c3d4976ac01d",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f15da367aabb4f459c87e0f463dbb709",
            "value": 100
          }
        },
        "c6e11dadfff94c4882a2fdd60bf2016d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a584dc207b5b47fb92ac0aceb8a3524e",
            "placeholder": "​",
            "style": "IPY_MODEL_c53560aed611476faff78deaf351bab3",
            "value": " 100/100 [35:09&lt;00:00, 19.25s/it]"
          }
        },
        "12b59f568c7d4d2681ac7777320f2e04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bd1e775cef945678d0b8edfefc38619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aa0ade568394b09aedbc47b0c7ba7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b623202a18843358f31c3d4976ac01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f15da367aabb4f459c87e0f463dbb709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a584dc207b5b47fb92ac0aceb8a3524e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c53560aed611476faff78deaf351bab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}